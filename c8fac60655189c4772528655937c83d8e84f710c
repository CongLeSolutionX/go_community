{
  "comments": [
    {
      "key": {
        "uuid": "2a4cb72f_b500f731",
        "filename": "src/io/pipe.go",
        "patchSetId": 1
      },
      "lineNbr": 75,
      "author": {
        "id": 6365
      },
      "writtenOn": "2017-09-22T04:09:41Z",
      "side": 1,
      "message": "I like the idea of using channels for the rendezvous, but I think you need a more explicit locking discipline for “head of the Write queue”.\n\nThe comment for the Pipe function says, “the individual calls will be gated sequentially”. That seems to imply that the payload of each Write must be fully exhausted before the next Write is allowed to proceed, but I don\u0027t see how this implementation satisfies that property.\n\nFurthermore, if you have multiple concurrent Read calls *and* multiple concurrent Write calls, I think it\u0027s possible for the rdCh send from one Read to go to the opposite (unpaired) Write.\n\n(Does this pass tests with a high GOMAXPROCS? If so, we may need to revisit the thoroughness of the tests...)",
      "revId": "c8fac60655189c4772528655937c83d8e84f710c",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "2d810c9d_c0a52c19",
        "filename": "src/io/pipe.go",
        "patchSetId": 1
      },
      "lineNbr": 75,
      "author": {
        "id": 6365
      },
      "writtenOn": "2017-09-22T05:15:01Z",
      "side": 1,
      "message": "Here\u0027s a suggestion based on combining your idea here with the general structure of https://github.com/cespare/misc/pull/1.\n\nThree channels:\np :\u003d \u0026pipe{\n\tsem: make(chan token, 1),\n\twrCh: make(chan []byte),\n\tdone: make(chan struct),\n}\n\n(plus a sync.Mutex or sync.Once guarding channel-closing and error-setting).\n\n\nWrite is as follows:\n\nfunc (p *pipe) Write(b []byte) (n int, err error) {\n\tselect {\n\tcase \u003c-p.done:\n\t\treturn …\n\tcase p.sem \u003c- token{}:\n\t\tdefer func() { \u003c-p.sem }()\n\t}\n\n\tinitLen :\u003d len(b)\n\tfor {\n\t\tselect {\n\t\tcase p.wrCh \u003c- b:\n\t\t\tb \u003d \u003c-p.wrCh\n\t\tcase \u003c-p.done:\n\t\t\treturn initLen - len(b), …\n\t\t}\n\t\tif len(b) \u003d\u003d 0 {\n\t\t\treturn initLen, nil\n\t\t}\n\t}\n}\n\nRead is similar to what you have now, but returns the slice over the first channel (to reduce the number of channels needed):\n\nfunc (p *pipe) Read(b []byte) (n int, err error) {\n\tselect {\n\tcase \u003c-p.done:\n\t\treturn 0, p.readCloseError()\n\tdefault:\n\t}\n\n\tselect {\n\tcase bw :\u003d \u003c-p.wrCh:\n\t\tnr :\u003d copy(b, bw)\n\t\tp.wrCh \u003c- b[nr:]\n\t\treturn nr, nil\n\tcase \u003c-p.done:\n\t\treturn 0, p.readCloseError()\n\t}\n}",
      "parentUuid": "2a4cb72f_b500f731",
      "revId": "c8fac60655189c4772528655937c83d8e84f710c",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ade139f4_74342f59",
        "filename": "src/io/pipe.go",
        "patchSetId": 1
      },
      "lineNbr": 75,
      "author": {
        "id": 9735
      },
      "writtenOn": "2017-09-22T19:21:36Z",
      "side": 1,
      "message": "The use of a single \"chan []byte\" is interesting, but it actually creates the possibility of a race unless we add a semaphore to Read as well. This can occur if there are concurrent Read operations, in which case, one of the Reads can accidentally pick up the response from a Read, instead of the Write it was intended for. The use of two channels makes it very clear that wrCh is only in the direction of Write-\u003eRead, and rdCh is only in the direction of Read-\u003eWrite, with no possibility of other competing goroutines swooping in and stealing the result.\n\nAlso, we can\u0027t do this:\n\tselect {\n\tcase \u003c-p.done:\n\t\treturn …\n\tcase p.sem \u003c- token{}:\n\t\tdefer func() { \u003c-p.sem }()\n\t}\n\nSince \u003c-p.done should take precedence over the availability of the semaphore.\nWell technically, it will work out since we are guaranteed that there are no Readers since Read has the same check, and so we will hit the \"case \u003c-p.done\" case down below, but that\u0027s a roundabout way to reason about this.\n\n\u003e I think you need a more explicit locking discipline for “head of the Write queue”.\n\nThere were no tests guaranteeing this behavior, so I intentionally dropped, but based on the reading of the documentation behavior, I think we should keep it. I added a simple mutex to serialize the entirety of the Write and added some tests to heavily test concurrent reads and writes.\n\nThis passes:\n $ go.dev test -run PipeConcurrent -count\u003d1000\n $ go.dev test -race -run PipeConcurrent -count\u003d100",
      "parentUuid": "2d810c9d_c0a52c19",
      "revId": "c8fac60655189c4772528655937c83d8e84f710c",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6ab6bd38_6008b94e",
        "filename": "src/io/pipe.go",
        "patchSetId": 1
      },
      "lineNbr": 75,
      "author": {
        "id": 6365
      },
      "writtenOn": "2017-10-04T18:16:31Z",
      "side": 1,
      "message": "\u003e one of the Reads can accidentally pick up the response from a Read, instead of the Write it was intended for.\n\nAh, good point. Even if we have Read explicitly check for a 0-length payload, we could get into an arbitrarily long cycle of 0-sends among Readers before the slice finally returns to the Writer.\n\n\u003e Also, we can\u0027t do this:\n\u003e \tselect {\n\u003e \tcase \u003c-p.done:\n\u003e \t\treturn …\n\u003e \tcase p.sem \u003c- token{}:\n\u003e \t\tdefer func() { \u003c-p.sem }()\n\u003e \t}\n\u003e \n\u003e Since \u003c-p.done should take precedence over the availability of the semaphore.\n\nI was thinking that Close would tombstone p.sem (by sending to it without a corresponding receive). That does mean that Close would potentially need to wait for a pending Write call to wake up and return, but that should happen quickly once p.done is closed anyway.",
      "parentUuid": "ade139f4_74342f59",
      "revId": "c8fac60655189c4772528655937c83d8e84f710c",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "9d35749e_509adbce",
        "filename": "src/io/pipe.go",
        "patchSetId": 1
      },
      "lineNbr": 75,
      "author": {
        "id": 9735
      },
      "writtenOn": "2017-10-09T21:13:41Z",
      "side": 1,
      "message": "The advantage of a sync.Mutex approach is that only the Write method needs to know about the mutex. While, the \"tombstone\" channel approach now has both Write and Close also accessing that field.\n\nCorrect me if I\u0027m wrong, the main advantage of a semaphore channel is that you can select over it, while you can\u0027t do that with a sync.Mutex? I don\u0027t believe selecting over the done channel at the same time as the semaphore provides a much of a benefit (concurrent Writers is already a pretty rare use-case).",
      "parentUuid": "6ab6bd38_6008b94e",
      "revId": "c8fac60655189c4772528655937c83d8e84f710c",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": true
    }
  ]
}