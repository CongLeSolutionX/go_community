{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "588eb31b_869ce4f2",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 5976
      },
      "writtenOn": "2024-01-27T09:01:31Z",
      "side": 1,
      "message": "TryBots beginning. Status page: https://farmer.golang.org/try?commit\u003d4e0d2179\n",
      "tag": "autogenerated:trybots~beginning",
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b4cce902_0ef55c8f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 5976
      },
      "writtenOn": "2024-01-27T09:13:44Z",
      "side": 1,
      "message": "TryBots are happy.\n\n",
      "parentUuid": "588eb31b_869ce4f2",
      "tag": "autogenerated:trybots~happy",
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "bdc6279c_c67cbc1f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 66298
      },
      "writtenOn": "2024-01-27T09:40:00Z",
      "side": 1,
      "message": "curious: is there an existing procedure that get us closer to the failure conditions we saw intermittently after the last cl was merged? \n\ni.e: should one consider just running the TryBots a few more times, or is there a  smarter way that one could assure this updated cl won\u0027t cause the same sorts of build failures?",
      "parentUuid": "b4cce902_0ef55c8f",
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "33f71c3c_b6000622",
        "filename": "src/net/http/client_test.go",
        "patchSetId": 4
      },
      "lineNbr": 2138,
      "author": {
        "id": 6365
      },
      "writtenOn": "2024-01-29T15:22:19Z",
      "side": 1,
      "message": "Why allocate a separate channel here instead of using `r.Context().Done()`?",
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d8a5d7c5_774a15c1",
        "filename": "src/net/http/client_test.go",
        "patchSetId": 4
      },
      "lineNbr": 2138,
      "author": {
        "id": 66298
      },
      "writtenOn": "2024-01-29T23:49:06Z",
      "side": 1,
      "message": "That\u0027s actually Damien\u0027s methodology there; https://go-review.googlesource.com/c/go/+/533119/comment/9133758c_cc35a308/\n\nMy original test didn\u0027t even use channels. `r.Context().Done()` would indeed be a more reasonable way to go if one insists on using channels within this test.",
      "parentUuid": "33f71c3c_b6000622",
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "630960bf_17dca64b",
        "filename": "src/net/http/client_test.go",
        "patchSetId": 4
      },
      "lineNbr": 2142,
      "author": {
        "id": 6365
      },
      "writtenOn": "2024-01-29T15:10:46Z",
      "side": 1,
      "message": "In general any test that relies on timeout behavior either needs a timeout several orders of magnitude longer than the test should ever actually take (such as 5 minutes instead of 5 milliseconds), or needs a retry loop to scale the timeout appropriately to the platform it is running on (see [`runTimeSensitiveTest`](https://cs.opensource.google/go/go/+/master:src/net/http/serve_test.go;l\u003d5831-5844;drc\u003d547eb8d699a63512cf58c7eeae5517ead7debf50)).",
      "range": {
        "startLine": 2141,
        "startChar": 0,
        "endLine": 2142,
        "endChar": 37
      },
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ba9171d2_12117d7f",
        "filename": "src/net/http/client_test.go",
        "patchSetId": 4
      },
      "lineNbr": 2145,
      "author": {
        "id": 6365
      },
      "writtenOn": "2024-01-29T15:22:19Z",
      "side": 1,
      "message": "It isn\u0027t clear to me why this error should be `context.DeadlineExceeded` at all.\n\n1. From the test failures in https://go.dev/issue/65287, it seems clear that the `Client.Timeout exceeded while awaiting headers` error returned from `Dial` does not currently wrap `context.DeadlineExceeded`, and it might be impossible for that error to do so with the existing API because `net.AddrError.Err` is stringly-typed (compare #63116).\n\n2. This looks like a failure of abstraction. In this call, there is no user-visible `context.Context` whose deadline is exceeded, so from a user\u0027s perspective, getting back an error wrapping `context.DeadlineExceeded` is surprising. (I would instead expect the error to wrap a [`net.Error`](https://pkg.go.dev/net#Error) for which `err.Timeout()` returns `true`, but perhaps we already have a test for that?)",
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d92536e4_4f377fe1",
        "filename": "src/net/http/client_test.go",
        "patchSetId": 4
      },
      "lineNbr": 2145,
      "author": {
        "id": 5305
      },
      "writtenOn": "2024-01-29T22:07:42Z",
      "side": 1,
      "message": "The test failures in #65287 seem to point at a race between two timeouts, one being the read timeout on the underlying net.Conn (which results Read returning a net.Error) and the other being the overall request timeout. Depending on which one wins, we get a different error.\n\nI don\u0027t know why increasing Client.Timeout to 5ms would affect this race; I\u0027m dubious that it\u0027s actually going to fix the problem.\n\nHowever, the presence of this race makes me dubious about this change in general--wrapping the underlying error isn\u0027t useful if the underlying error isn\u0027t consistent. And we\u0027re already consistently returning an error which implements `net.Error` for which `err.Timeout()` returns true, so there\u0027s an existing way to detect timeouts that\u0027s independent of the source of the error.\n\nTo summarize (and pretty much just reiterate what Bryan has said):\n\n1. Changing the Timeout duration isn\u0027t going to fix this test. If changing the duration has an effect, the test is flaky.\n2. Wrapping the underlying timeout error is only useful if the error that occurs on timeout is consistent. It isn\u0027t, so either wrapping the error is not useful or we need to do more significant work on what underlying errors are returned on timeout.",
      "parentUuid": "ba9171d2_12117d7f",
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "72adc2a4_303c5382",
        "filename": "src/net/http/client_test.go",
        "patchSetId": 4
      },
      "lineNbr": 2145,
      "author": {
        "id": 66298
      },
      "writtenOn": "2024-01-29T23:41:30Z",
      "side": 1,
      "message": "sounds to me like if I want to see this change see the light of day I\u0027m going to have to dig deeper into our race condition(s) seen within the build failures and potentially do a bit more error wrapping. Does this sound roughly correct as to the direction I\u0027d need to head?\n\nas for the various comments about this being necessary or not; this isn\u0027t a lone opinion of mine, of course. The way error wrapping in go has been implemented, errors are generally expected to be wrapped these days. \n\nit becomes quite confusing when (various) linters and fellow developers lead you into the habit of wrapping and handling wrapped errors, only to stumble upon stdlib code from before this was common. these string returns in older error type implementations definitely cause a decent amount of confusion. the current behavior I\u0027m attempting to correct here simply is not expected in 2024.",
      "parentUuid": "d92536e4_4f377fe1",
      "revId": "4e0d217989b8ec0118ba06a2568ff6e75de897a0",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    }
  ]
}