{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "82b8bd23_ccdec2e6",
        "filename": "src/cmd/compile/internal/ssa/gen/ARM64.rules",
        "patchSetId": 2
      },
      "lineNbr": 1785,
      "author": {
        "id": 5200
      },
      "writtenOn": "2021-03-15T21:29:18Z",
      "side": 1,
      "message": "lc \u003c 64 probably isn\u0027t necessary. All SLLconst operations should guarantee the shift amount is 0-63 inclusive.\nAlthough looking now, we don\u0027t assert that for ARM64 shift ops. Probably we should (e.g. see SHLQconst in AMD64Ops.go) and audit any rewrites that generate SLLconst (and related ops).\nAlso lc is int64, not uint64, so negative numbers would pass, which you probably don\u0027t want.\n\nYou can change this to 0 \u003c\u003d lc \u0026\u0026 lc \u003c 64 for now, or do the cleanup I mentioned first, then rebase this on top of that, and get rid of the condition.",
      "range": {
        "startLine": 1785,
        "startChar": 31,
        "endLine": 1785,
        "endChar": 38
      },
      "revId": "43caecf9fdde59a445355d54dca9b1499475f5b5",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    }
  ]
}