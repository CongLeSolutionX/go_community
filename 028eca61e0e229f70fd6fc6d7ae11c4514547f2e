{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "41aac2c5_dac19f28",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 5200
      },
      "writtenOn": "2024-05-17T15:20:25Z",
      "side": 1,
      "message": "Do we have any data on what amd processors do? My understanding is that recent amd processors set the erms bit and have a good implementation.\nWhat intel processors set the erms bit but don\u0027t have a good implementation? My understanding is that it is pre ivy bridge, but I don\u0027t know with certainty. Can we detect that cutoff somehow?\n\nThe current conditions were added in 2016, so they could definitely use an update.\nhttps://go-review.googlesource.com/c/go/+/29590",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "68ee20ce_1f67683b",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 5846
      },
      "writtenOn": "2024-05-29T19:18:00Z",
      "side": 1,
      "message": "For modern AMDs I have 3400g, 3800x, 5800x3d (and 5600x, 5950x). I can test around a bit if they work well if we just use rep mov instead for longer moves. I dont think we would care much for performance pre Ryzen (2017).\n\nFor Intel I guess only Sandy and IvyBridge have ERMS+AVX AND wont work well with AVX custom loop. These CPUs are from around 2011/2012. I have a sandy bridge AVX CPU I can test against.\n\nI can benchmark around with rep mov vs avx path on different generations but it will take me a few weeks.\n\nIdeally (and I would prefer) we shouldnt need to special case AMD vs INTEL and just rely on CPUID flags. That means we can just always use rep mov if ERMS is enabled if that also works well on Ryzen. Then the other decision to make is if destination is unaligned we keep a custom AVX loop or this can be optimized/simplified too.",
      "parentUuid": "41aac2c5_dac19f28",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "fdab92b8_95cb20bc",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-05-30T01:53:47Z",
      "side": 1,
      "message": "Sorry, we don\u0027t have any AMD processors\u0027 data.\nThe current ERMS strategy is basically the same as glibc. https://sourceware.org/git/?p\u003dglibc.git;a\u003dblob;f\u003dsysdeps/x86/dl-cacheinfo.h;h\u003df34d12846caf9422c07264e744baf20e45742a12;hb\u003daa4249266e9906c4bc833e4847f4d8feef59504f#l992\nI think for now just checking the ERMS bits is acceptable, at least for modern Intel CPUs.",
      "parentUuid": "41aac2c5_dac19f28",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a215c987_0be7e038",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 16006
      },
      "writtenOn": "2024-06-03T10:10:14Z",
      "side": 1,
      "message": "I think it would be good to add more impact analysis.\n\nDoes this make Ivy Bridge worse? (that can be ok as a tradeoff but we should at least mention it so its an expected side effect and tradeoff)",
      "parentUuid": "fdab92b8_95cb20bc",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "76cba74a_c9c57ace",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-04T05:39:35Z",
      "side": 1,
      "message": "@moehrmann@google.com  This will not make Ivy Bridge worse, because the previous code \"processor \u003d\u003d 0x306A0 || processor \u003d\u003d 0x306E0\" is for Ivy Bridge.",
      "parentUuid": "a215c987_0be7e038",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1f41c0af_cc2be4b5",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 16006
      },
      "writtenOn": "2024-06-04T06:00:34Z",
      "side": 1,
      "message": "ack. there were many other Intel generations until Sapphire Rapids. As far as I understand this will switch them from AVX to rep mov. There was a reason to have AVX path in the first place and not use rep mov. Will any of the other generations e.g. Haswell, Skylake, ... get worse performance because of using rep mov instead of AVX custom path?",
      "parentUuid": "76cba74a_c9c57ace",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "67ba949e_22ce8681",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-04T08:16:37Z",
      "side": 1,
      "message": "@moehrmann@google.com I think it will not get worse performance. I will try my best to get some other generations machines, test and prove it. And this might take some time.",
      "parentUuid": "1f41c0af_cc2be4b5",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5a7a33c4_33864678",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-11T05:33:59Z",
      "side": 1,
      "message": "@moehrmann@google.com \n\nCASCADE LAKE:\n```\ngoos: linux\ngoarch: amd64\npkg: runtime\ncpu: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz\n                │ ./pr/old.txt │             ./pr/new.txt             │\n                │    sec/op    │    sec/op     vs base                │\nMemmove/2048-96    19.43n ± 1%   29.67n ± 15%  +52.66% (p\u003d0.000 n\u003d10)\nMemmove/4096-96    38.57n ± 1%   45.10n ±  3%  +16.93% (p\u003d0.000 n\u003d10)\ngeomean            27.38n        36.58n        +33.61%\n\n                │ ./pr/old.txt │             ./pr/new.txt              │\n                │     B/s      │      B/s       vs base                │\nMemmove/2048-96   98.12Gi ± 1%   64.29Gi ± 13%  -34.48% (p\u003d0.000 n\u003d10)\nMemmove/4096-96   98.90Gi ± 1%   84.59Gi ±  3%  -14.47% (p\u003d0.000 n\u003d10)\ngeomean           98.51Gi        73.74Gi        -25.14%\n```\nCASCADE LAKE (VM):\n```\ngoos: linux\ngoarch: amd64\npkg: runtime\ncpu: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz\n               │  ./old.txt  │              ./new.txt              │\n               │   sec/op    │   sec/op     vs base                │\nMemmove/2048-2   24.91n ± 2%   36.95n ± 2%  +48.33% (p\u003d0.000 n\u003d10)\nMemmove/4096-2   47.91n ± 1%   58.03n ± 2%  +21.13% (p\u003d0.000 n\u003d10)\ngeomean          34.55n        46.31n       +34.05%\n\n               │  ./old.txt   │              ./new.txt               │\n               │     B/s      │     B/s       vs base                │\nMemmove/2048-2   76.57Gi ± 2%   51.62Gi ± 2%  -32.59% (p\u003d0.000 n\u003d10)\nMemmove/4096-2   79.62Gi ± 1%   65.73Gi ± 2%  -17.45% (p\u003d0.000 n\u003d10)\ngeomean          78.08Gi        58.25Gi       -25.40%\n```\n\nSKYLAKE:\n```\ngoos: linux\ngoarch: amd64\npkg: runtime\ncpu: Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz\n             │  ./old.txt  │               ./new.txt                │\n             │   sec/op    │    sec/op      vs base                 │\nMemmove/2048   19.64n ± 0%   70.47n ±   1%  +258.78% (p\u003d0.000 n\u003d10)\nMemmove/4096   37.73n ± 0%   33.31n ± 137%         ~ (p\u003d0.469 n\u003d10)\ngeomean        27.22n        48.44n          +77.97%\n\n             │  ./old.txt   │               ./new.txt               │\n             │     B/s      │      B/s       vs base                │\nMemmove/2048   97.12Gi ± 0%   27.07Gi ±  1%  -72.13% (p\u003d0.000 n\u003d10)\nMemmove/4096   101.1Gi ± 0%   114.5Gi ± 58%        ~ (p\u003d0.481 n\u003d10)\ngeomean        99.10Gi        55.68Gi        -43.82%\n```\nUnfortunately I could not find any more older platform machines. I did some testing on a VM Broadwell, but it does not support the ERMS feature.\n\nAnd as the results show, You are right, the performance of ERMS repmovsb is worse on these platforms.\n\nI think using the original allowlist strategy is much better here.\n\n@khr@golang.org what do you think?",
      "parentUuid": "67ba949e_22ce8681",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "176682a2_141e9833",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 5200
      },
      "writtenOn": "2024-06-11T17:13:04Z",
      "side": 1,
      "message": "Reading the optimization manual, we should consider both the erms bit (3.7.6) and the fast_short_rep_movsb bit (3.7.6.1). I think the latter might help us here? On those processors where you saw slowdown, is that latter bit set?",
      "parentUuid": "5a7a33c4_33864678",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f782df92_fc01e1a3",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-12T03:01:29Z",
      "side": 1,
      "message": "@khr@golang.org FSRM (Fast Short Rep Movsb) is a feature that has been supported by Intel CPUs since the Ice Lake generation, so on the older platform, there is no FSRM. \n\nAs the manual said: \n\n\u003e Beginning with processors based on Ice Lake Client microarchitecture, REP MOVSB performance of short operations\n\u003e is enhanced. **The enhancement applies to string lengths between 1 and 128 bytes long.** Support for fast-short REP\n\u003e MOVSB is enumerated by the CPUID feature flag: CPUID [EAX\u003d7H, ECX\u003d0H).EDX.FAST_SHORT_REP_MOVSB[bit 4] \u003d 1.\n\u003e There is no change in the REP STOS performance.\n\nIt seems unlikely that the FSRM will have any effect on data of 2KB in size.\nBut I think it is OK to use it as a trick: a CPU with FSRM support often offered better performance when copying large amounts of data using REP MOVSB (not always ). And this may not be causally related.",
      "parentUuid": "176682a2_141e9833",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "db15ea44_a78e153b",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 5200
      },
      "writtenOn": "2024-06-12T04:24:56Z",
      "side": 1,
      "message": "Yes, that\u0027s what I was thinking. Make using REP MOV conditional on ERMS \u0026\u0026 FSRM. It may not be exactly the condition we want, but it should be right for all current and future chips. That \"future chips\" part is what I really want to ensure so we don\u0027t have to revisit this every processor generation.",
      "parentUuid": "f782df92_fc01e1a3",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "14fe8955_a984de91",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-14T05:26:24Z",
      "side": 1,
      "message": "@khr@golang.org OK, I will update the code as you want",
      "parentUuid": "db15ea44_a78e153b",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "cabfb34c_562cc837",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 87,
      "author": {
        "id": 5200
      },
      "writtenOn": "2024-05-17T15:20:25Z",
      "side": 1,
      "message": "This test seems backwards? It skips erms if the destination is aligned.",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "af23706c_06d5d55c",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 87,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-05-30T01:53:47Z",
      "side": 1,
      "message": "\u003e This test seems backwards? It skips erms if the destination is aligned.\n\nThank you for point this! It is my mistake.",
      "parentUuid": "cabfb34c_562cc837",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6fd881a6_83505060",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 107,
      "author": {
        "id": 16006
      },
      "writtenOn": "2024-06-03T10:10:14Z",
      "side": 1,
      "message": "why not use fwdBy8 with repmovsq? If rep movb is always faster than we change that block to also use rep movsb and avoid having two different rep mov blocks.",
      "range": {
        "startLine": 107,
        "startChar": 0,
        "endLine": 107,
        "endChar": 5
      },
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "101ffa84_68730a93",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 107,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-04T05:39:35Z",
      "side": 1,
      "message": "@moehrmann@google.com\nAccording to https://www.intel.com/content/www/us/en/content-details/671488/intel-64-and-ia-32-architectures-optimization-reference-manual-volume-1.html 3.7.5, REP MOVSD+B is faster than REP MOVSB if the CPU does not support ERMS. I think REP MOVSQ is a good path for memmove if the CPU  does not support ERMS and AVX. Also if we do not care about those old CPUs ( over 10 years ), I think just keep one REP MOVSB block is OK. Thank you.",
      "parentUuid": "6fd881a6_83505060",
      "range": {
        "startLine": 107,
        "startChar": 0,
        "endLine": 107,
        "endChar": 5
      },
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5928e72f_c0066a1d",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 107,
      "author": {
        "id": 13315
      },
      "writtenOn": "2024-06-13T16:08:02Z",
      "side": 1,
      "message": "It is important that we write pointers atomically, that is, either all bits in a pointer is updated, or none. MOVSQ makes sure we write 8 bytes a time. I\u0027m not sure if MOVSB has this guarantee? Using MOVSB unconditionally can be problematic.",
      "parentUuid": "101ffa84_68730a93",
      "range": {
        "startLine": 107,
        "startChar": 0,
        "endLine": 107,
        "endChar": 5
      },
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "3994497b_4c09f218",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 107,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-14T05:26:24Z",
      "side": 1,
      "message": "@cherryyz@google.com Using REP MOVSB is not a new method added in this pull request, the behavior has been here for a long time.",
      "parentUuid": "5928e72f_c0066a1d",
      "range": {
        "startLine": 107,
        "startChar": 0,
        "endLine": 107,
        "endChar": 5
      },
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6bdc609f_ff508227",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 107,
      "author": {
        "id": 13315
      },
      "writtenOn": "2024-06-14T14:31:31Z",
      "side": 1,
      "message": "If I read the code correctly, the old code uses REP MOVSQ for 8-byte aligned words (fwdBy8). But the new code skips MOVSQ and always uses MOVSB.",
      "parentUuid": "3994497b_4c09f218",
      "range": {
        "startLine": 107,
        "startChar": 0,
        "endLine": 107,
        "endChar": 5
      },
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "114ac3b0_23350831",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 107,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-18T13:40:16Z",
      "side": 1,
      "message": "@cherryyz@google.com\n\"the old code uses REP MOVSQ for 8-byte aligned words (fwdBy8).\" :  Yes, and it does not check the pointer problem either, if the addresses are not aligned you may still enter the rep movsb path.\nI have updated the code, the new code uses MOVSQ to ensure that writing pointers atomically as possible",
      "parentUuid": "6bdc609f_ff508227",
      "range": {
        "startLine": 107,
        "startChar": 0,
        "endLine": 107,
        "endChar": 5
      },
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    }
  ]
}