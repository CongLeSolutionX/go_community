{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "41aac2c5_dac19f28",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 5200
      },
      "writtenOn": "2024-05-17T15:20:25Z",
      "side": 1,
      "message": "Do we have any data on what amd processors do? My understanding is that recent amd processors set the erms bit and have a good implementation.\nWhat intel processors set the erms bit but don\u0027t have a good implementation? My understanding is that it is pre ivy bridge, but I don\u0027t know with certainty. Can we detect that cutoff somehow?\n\nThe current conditions were added in 2016, so they could definitely use an update.\nhttps://go-review.googlesource.com/c/go/+/29590",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "68ee20ce_1f67683b",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 5846
      },
      "writtenOn": "2024-05-29T19:18:00Z",
      "side": 1,
      "message": "For modern AMDs I have 3400g, 3800x, 5800x3d (and 5600x, 5950x). I can test around a bit if they work well if we just use rep mov instead for longer moves. I dont think we would care much for performance pre Ryzen (2017).\n\nFor Intel I guess only Sandy and IvyBridge have ERMS+AVX AND wont work well with AVX custom loop. These CPUs are from around 2011/2012. I have a sandy bridge AVX CPU I can test against.\n\nI can benchmark around with rep mov vs avx path on different generations but it will take me a few weeks.\n\nIdeally (and I would prefer) we shouldnt need to special case AMD vs INTEL and just rely on CPUID flags. That means we can just always use rep mov if ERMS is enabled if that also works well on Ryzen. Then the other decision to make is if destination is unaligned we keep a custom AVX loop or this can be optimized/simplified too.",
      "parentUuid": "41aac2c5_dac19f28",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "fdab92b8_95cb20bc",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-05-30T01:53:47Z",
      "side": 1,
      "message": "Sorry, we don\u0027t have any AMD processors\u0027 data.\nThe current ERMS strategy is basically the same as glibc. https://sourceware.org/git/?p\u003dglibc.git;a\u003dblob;f\u003dsysdeps/x86/dl-cacheinfo.h;h\u003df34d12846caf9422c07264e744baf20e45742a12;hb\u003daa4249266e9906c4bc833e4847f4d8feef59504f#l992\nI think for now just checking the ERMS bits is acceptable, at least for modern Intel CPUs.",
      "parentUuid": "41aac2c5_dac19f28",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a215c987_0be7e038",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 16006
      },
      "writtenOn": "2024-06-03T10:10:14Z",
      "side": 1,
      "message": "I think it would be good to add more impact analysis.\n\nDoes this make Ivy Bridge worse? (that can be ok as a tradeoff but we should at least mention it so its an expected side effect and tradeoff)",
      "parentUuid": "fdab92b8_95cb20bc",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "76cba74a_c9c57ace",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-04T05:39:35Z",
      "side": 1,
      "message": "@moehrmann@google.com  This will not make Ivy Bridge worse, because the previous code \"processor \u003d\u003d 0x306A0 || processor \u003d\u003d 0x306E0\" is for Ivy Bridge.",
      "parentUuid": "a215c987_0be7e038",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1f41c0af_cc2be4b5",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 16006
      },
      "writtenOn": "2024-06-04T06:00:34Z",
      "side": 1,
      "message": "ack. there were many other Intel generations until Sapphire Rapids. As far as I understand this will switch them from AVX to rep mov. There was a reason to have AVX path in the first place and not use rep mov. Will any of the other generations e.g. Haswell, Skylake, ... get worse performance because of using rep mov instead of AVX custom path?",
      "parentUuid": "76cba74a_c9c57ace",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "67ba949e_22ce8681",
        "filename": "src/runtime/cpuflags_amd64.go",
        "patchSetId": 3
      },
      "lineNbr": 17,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-04T08:16:37Z",
      "side": 1,
      "message": "@moehrmann@google.com I think it will not get worse performance. I will try my best to get some other generations machines, test and prove it. And this might take some time.",
      "parentUuid": "1f41c0af_cc2be4b5",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "cabfb34c_562cc837",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 87,
      "author": {
        "id": 5200
      },
      "writtenOn": "2024-05-17T15:20:25Z",
      "side": 1,
      "message": "This test seems backwards? It skips erms if the destination is aligned.",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "af23706c_06d5d55c",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 87,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-05-30T01:53:47Z",
      "side": 1,
      "message": "\u003e This test seems backwards? It skips erms if the destination is aligned.\n\nThank you for point this! It is my mistake.",
      "parentUuid": "cabfb34c_562cc837",
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6fd881a6_83505060",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 107,
      "author": {
        "id": 16006
      },
      "writtenOn": "2024-06-03T10:10:14Z",
      "side": 1,
      "message": "why not use fwdBy8 with repmovsq? If rep movb is always faster than we change that block to also use rep movsb and avoid having two different rep mov blocks.",
      "range": {
        "startLine": 107,
        "startChar": 0,
        "endLine": 107,
        "endChar": 5
      },
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "101ffa84_68730a93",
        "filename": "src/runtime/memmove_amd64.s",
        "patchSetId": 3
      },
      "lineNbr": 107,
      "author": {
        "id": 3406889
      },
      "writtenOn": "2024-06-04T05:39:35Z",
      "side": 1,
      "message": "@moehrmann@google.com\nAccording to https://www.intel.com/content/www/us/en/content-details/671488/intel-64-and-ia-32-architectures-optimization-reference-manual-volume-1.html 3.7.5, REP MOVSD+B is faster than REP MOVSB if the CPU does not support ERMS. I think REP MOVSQ is a good path for memmove if the CPU  does not support ERMS and AVX. Also if we do not care about those old CPUs ( over 10 years ), I think just keep one REP MOVSB block is OK. Thank you.",
      "parentUuid": "6fd881a6_83505060",
      "range": {
        "startLine": 107,
        "startChar": 0,
        "endLine": 107,
        "endChar": 5
      },
      "revId": "028eca61e0e229f70fd6fc6d7ae11c4514547f2e",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    }
  ]
}