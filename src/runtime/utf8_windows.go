// Code generated by golang.org/x/tools/cmd/bundle command:
//   $ bundle unicode/utf8 runtime utf8

// Package utf8 implements functions and constants to support text encoded in
// UTF-8. It includes functions to translate between runes and UTF-8 byte sequences.
//
package runtime

import ()

// Numbers fundamental to the encoding.
const (
	utf8RuneError = '\uFFFD'     // the "error" Rune or "Unicode replacement character"
	utf8RuneSelf  = 0x80         // characters below Runeself are represented as themselves in a single byte.
	utf8MaxRune   = '\U0010FFFF' // Maximum valid Unicode code point.
	utf8UTFMax    = 4            // maximum number of bytes of a UTF-8 encoded Unicode character.
)

// Code points in the surrogate range are not valid for UTF-8.
const (
	utf8surrogateMin = 0xD800
	utf8surrogateMax = 0xDFFF
)

const (
	utf8t1 = 0x00 // 0000 0000
	utf8tx = 0x80 // 1000 0000
	utf8t2 = 0xC0 // 1100 0000
	utf8t3 = 0xE0 // 1110 0000
	utf8t4 = 0xF0 // 1111 0000
	utf8t5 = 0xF8 // 1111 1000

	utf8maskx = 0x3F // 0011 1111
	utf8mask2 = 0x1F // 0001 1111
	utf8mask3 = 0x0F // 0000 1111
	utf8mask4 = 0x07 // 0000 0111

	utf8rune1Max = 1<<7 - 1
	utf8rune2Max = 1<<11 - 1
	utf8rune3Max = 1<<16 - 1
)

func utf8decodeRuneInternal(p []byte) (r rune, size int, short bool) {
	n := len(p)
	if n < 1 {
		return utf8RuneError, 0, true
	}
	c0 := p[0]

	if c0 < utf8tx {
		return rune(c0), 1, false
	}

	if c0 < utf8t2 {
		return utf8RuneError, 1, false
	}

	if n < 2 {
		return utf8RuneError, 1, true
	}
	c1 := p[1]
	if c1 < utf8tx || utf8t2 <= c1 {
		return utf8RuneError, 1, false
	}

	if c0 < utf8t3 {
		r = rune(c0&utf8mask2)<<6 | rune(c1&utf8maskx)
		if r <= utf8rune1Max {
			return utf8RuneError, 1, false
		}
		return r, 2, false
	}

	if n < 3 {
		return utf8RuneError, 1, true
	}
	c2 := p[2]
	if c2 < utf8tx || utf8t2 <= c2 {
		return utf8RuneError, 1, false
	}

	if c0 < utf8t4 {
		r = rune(c0&utf8mask3)<<12 | rune(c1&utf8maskx)<<6 | rune(c2&utf8maskx)
		if r <= utf8rune2Max {
			return utf8RuneError, 1, false
		}
		if utf8surrogateMin <= r && r <= utf8surrogateMax {
			return utf8RuneError, 1, false
		}
		return r, 3, false
	}

	if n < 4 {
		return utf8RuneError, 1, true
	}
	c3 := p[3]
	if c3 < utf8tx || utf8t2 <= c3 {
		return utf8RuneError, 1, false
	}

	if c0 < utf8t5 {
		r = rune(c0&utf8mask4)<<18 | rune(c1&utf8maskx)<<12 | rune(c2&utf8maskx)<<6 | rune(c3&utf8maskx)
		if r <= utf8rune3Max || utf8MaxRune < r {
			return utf8RuneError, 1, false
		}
		return r, 4, false
	}

	return utf8RuneError, 1, false
}

func utf8decodeRuneInStringInternal(s string) (r rune, size int, short bool) {
	n := len(s)
	if n < 1 {
		return utf8RuneError, 0, true
	}
	c0 := s[0]

	if c0 < utf8tx {
		return rune(c0), 1, false
	}

	if c0 < utf8t2 {
		return utf8RuneError, 1, false
	}

	if n < 2 {
		return utf8RuneError, 1, true
	}
	c1 := s[1]
	if c1 < utf8tx || utf8t2 <= c1 {
		return utf8RuneError, 1, false
	}

	if c0 < utf8t3 {
		r = rune(c0&utf8mask2)<<6 | rune(c1&utf8maskx)
		if r <= utf8rune1Max {
			return utf8RuneError, 1, false
		}
		return r, 2, false
	}

	if n < 3 {
		return utf8RuneError, 1, true
	}
	c2 := s[2]
	if c2 < utf8tx || utf8t2 <= c2 {
		return utf8RuneError, 1, false
	}

	if c0 < utf8t4 {
		r = rune(c0&utf8mask3)<<12 | rune(c1&utf8maskx)<<6 | rune(c2&utf8maskx)
		if r <= utf8rune2Max {
			return utf8RuneError, 1, false
		}
		if utf8surrogateMin <= r && r <= utf8surrogateMax {
			return utf8RuneError, 1, false
		}
		return r, 3, false
	}

	if n < 4 {
		return utf8RuneError, 1, true
	}
	c3 := s[3]
	if c3 < utf8tx || utf8t2 <= c3 {
		return utf8RuneError, 1, false
	}

	if c0 < utf8t5 {
		r = rune(c0&utf8mask4)<<18 | rune(c1&utf8maskx)<<12 | rune(c2&utf8maskx)<<6 | rune(c3&utf8maskx)
		if r <= utf8rune3Max || utf8MaxRune < r {
			return utf8RuneError, 1, false
		}
		return r, 4, false
	}

	return utf8RuneError, 1, false
}

// FullRune reports whether the bytes in p begin with a full UTF-8 encoding of a rune.
// An invalid encoding is considered a full Rune since it will convert as a width-1 error rune.
func utf8FullRune(p []byte) bool {
	_, _, short := utf8decodeRuneInternal(p)
	return !short
}

// FullRuneInString is like FullRune but its input is a string.
func utf8FullRuneInString(s string) bool {
	_, _, short := utf8decodeRuneInStringInternal(s)
	return !short
}

// DecodeRune unpacks the first UTF-8 encoding in p and returns the rune and
// its width in bytes. If p is empty it returns (RuneError, 0). Otherwise, if
// the encoding is invalid, it returns (RuneError, 1). Both are impossible
// results for correct UTF-8.
//
// An encoding is invalid if it is incorrect UTF-8, encodes a rune that is
// out of range, or is not the shortest possible UTF-8 encoding for the
// value. No other validation is performed.
func utf8DecodeRune(p []byte) (r rune, size int) {
	r, size, _ = utf8decodeRuneInternal(p)
	return
}

// DecodeRuneInString is like DecodeRune but its input is a string. If s is
// empty it returns (RuneError, 0). Otherwise, if the encoding is invalid, it
// returns (RuneError, 1). Both are impossible results for correct UTF-8.
//
// An encoding is invalid if it is incorrect UTF-8, encodes a rune that is
// out of range, or is not the shortest possible UTF-8 encoding for the
// value. No other validation is performed.
func utf8DecodeRuneInString(s string) (r rune, size int) {
	r, size, _ = utf8decodeRuneInStringInternal(s)
	return
}

// DecodeLastRune unpacks the last UTF-8 encoding in p and returns the rune and
// its width in bytes. If p is empty it returns (RuneError, 0). Otherwise, if
// the encoding is invalid, it returns (RuneError, 1). Both are impossible
// results for correct UTF-8.
//
// An encoding is invalid if it is incorrect UTF-8, encodes a rune that is
// out of range, or is not the shortest possible UTF-8 encoding for the
// value. No other validation is performed.
func utf8DecodeLastRune(p []byte) (r rune, size int) {
	end := len(p)
	if end == 0 {
		return utf8RuneError, 0
	}
	start := end - 1
	r = rune(p[start])
	if r < utf8RuneSelf {
		return r, 1
	}

	lim := end - utf8UTFMax
	if lim < 0 {
		lim = 0
	}
	for start--; start >= lim; start-- {
		if utf8RuneStart(p[start]) {
			break
		}
	}
	if start < 0 {
		start = 0
	}
	r, size = utf8DecodeRune(p[start:end])
	if start+size != end {
		return utf8RuneError, 1
	}
	return r, size
}

// DecodeLastRuneInString is like DecodeLastRune but its input is a string. If
// s is empty it returns (RuneError, 0). Otherwise, if the encoding is invalid,
// it returns (RuneError, 1). Both are impossible results for correct UTF-8.
//
// An encoding is invalid if it is incorrect UTF-8, encodes a rune that is
// out of range, or is not the shortest possible UTF-8 encoding for the
// value. No other validation is performed.
func utf8DecodeLastRuneInString(s string) (r rune, size int) {
	end := len(s)
	if end == 0 {
		return utf8RuneError, 0
	}
	start := end - 1
	r = rune(s[start])
	if r < utf8RuneSelf {
		return r, 1
	}

	lim := end - utf8UTFMax
	if lim < 0 {
		lim = 0
	}
	for start--; start >= lim; start-- {
		if utf8RuneStart(s[start]) {
			break
		}
	}
	if start < 0 {
		start = 0
	}
	r, size = utf8DecodeRuneInString(s[start:end])
	if start+size != end {
		return utf8RuneError, 1
	}
	return r, size
}

// RuneLen returns the number of bytes required to encode the rune.
// It returns -1 if the rune is not a valid value to encode in UTF-8.
func utf8RuneLen(r rune) int {
	switch {
	case r < 0:
		return -1
	case r <= utf8rune1Max:
		return 1
	case r <= utf8rune2Max:
		return 2
	case utf8surrogateMin <= r && r <= utf8surrogateMax:
		return -1
	case r <= utf8rune3Max:
		return 3
	case r <= utf8MaxRune:
		return 4
	}
	return -1
}

// EncodeRune writes into p (which must be large enough) the UTF-8 encoding of the rune.
// It returns the number of bytes written.
func utf8EncodeRune(p []byte, r rune) int {

	switch i := uint32(r); {
	case i <= utf8rune1Max:
		p[0] = byte(r)
		return 1
	case i <= utf8rune2Max:
		p[0] = utf8t2 | byte(r>>6)
		p[1] = utf8tx | byte(r)&utf8maskx
		return 2
	case i > utf8MaxRune, utf8surrogateMin <= i && i <= utf8surrogateMax:
		r = utf8RuneError
		fallthrough
	case i <= utf8rune3Max:
		p[0] = utf8t3 | byte(r>>12)
		p[1] = utf8tx | byte(r>>6)&utf8maskx
		p[2] = utf8tx | byte(r)&utf8maskx
		return 3
	default:
		p[0] = utf8t4 | byte(r>>18)
		p[1] = utf8tx | byte(r>>12)&utf8maskx
		p[2] = utf8tx | byte(r>>6)&utf8maskx
		p[3] = utf8tx | byte(r)&utf8maskx
		return 4
	}
}

// RuneCount returns the number of runes in p.  Erroneous and short
// encodings are treated as single runes of width 1 byte.
func utf8RuneCount(p []byte) int {
	i := 0
	var n int
	for n = 0; i < len(p); n++ {
		if p[i] < utf8RuneSelf {
			i++
		} else {
			_, size := utf8DecodeRune(p[i:])
			i += size
		}
	}
	return n
}

// RuneCountInString is like RuneCount but its input is a string.
func utf8RuneCountInString(s string) (n int) {
	for range s {
		n++
	}
	return
}

// RuneStart reports whether the byte could be the first byte of
// an encoded rune.  Second and subsequent bytes always have the top
// two bits set to 10.
func utf8RuneStart(b byte) bool { return b&0xC0 != 0x80 }

// Valid reports whether p consists entirely of valid UTF-8-encoded runes.
func utf8Valid(p []byte) bool {
	i := 0
	for i < len(p) {
		if p[i] < utf8RuneSelf {
			i++
		} else {
			_, size := utf8DecodeRune(p[i:])
			if size == 1 {

				return false
			}
			i += size
		}
	}
	return true
}

// ValidString reports whether s consists entirely of valid UTF-8-encoded runes.
func utf8ValidString(s string) bool {
	for i, r := range s {
		if r == utf8RuneError {

			_, size := utf8DecodeRuneInString(s[i:])
			if size == 1 {
				return false
			}
		}
	}
	return true
}

// ValidRune reports whether r can be legally encoded as UTF-8.
// Code points that are out of range or a surrogate half are illegal.
func utf8ValidRune(r rune) bool {
	switch {
	case r < 0:
		return false
	case utf8surrogateMin <= r && r <= utf8surrogateMax:
		return false
	case r > utf8MaxRune:
		return false
	}
	return true
}
