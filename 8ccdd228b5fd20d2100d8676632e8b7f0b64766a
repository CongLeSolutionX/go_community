{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "ba3c68f7_ee0b2f61",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 27462
      },
      "writtenOn": "2021-01-29T02:24:12Z",
      "side": 1,
      "message": "It seems that the failed windows case is not related to this patch. Is it possible to rerun the CI? ",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ae3ef397_e2cc52eb",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 27462
      },
      "writtenOn": "2021-01-31T04:10:16Z",
      "side": 1,
      "message": "Thanks! The CI is on green!",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "d4cb71c4_965b4cfc",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 5137
      },
      "writtenOn": "2021-02-01T19:29:20Z",
      "side": 1,
      "message": "Thank you for mailing this change, Wei! I\u0027ve added some suggestions for making the test reliable and also improving it, please take a look.",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "7a54dec6_dbb0c08a",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 6365
      },
      "writtenOn": "2021-02-02T15:43:02Z",
      "side": 1,
      "message": "That was #42637, fixed in CL 285720 (Jan. 25).\n\n(Most likely, PS3\u0027s base was before that commit.)",
      "parentUuid": "ba3c68f7_ee0b2f61",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ddda5c9c_565ad901",
        "filename": "src/net/http/fs_test.go",
        "patchSetId": 3
      },
      "lineNbr": 1422,
      "author": {
        "id": 5137
      },
      "writtenOn": "2021-02-01T19:29:20Z",
      "side": 1,
      "message": "In the past this kind of test caused flakes, perhaps we can recompose this code to ensure proper synchronization, and thus for every single test perhaps:\n\nfunc TestServeContentEOFsOnWriteTimeoutExceeded(t *testing.T) {\n        files :\u003d []string{\n                \"/file\",                 // size \u003c 512 bytes\n                \"/file-bigger-than-512\", // size \u003e 512 bytes\n        }\n\n        fileServer :\u003d FileServer(Dir(\"testdata\"))\n        for _, filename :\u003d range files {\n                filename :\u003d filename\n                t.Run(filename, func(t *testing.T) {\n                        var wg sync.WaitGroup\n                        // Ensure that the test ended.\n                        defer wg.Wait()\n\n                        timeoutHandler :\u003d HandlerFunc(func(rw ResponseWriter, req *Request) {\n                                wg.Wait()\n                                fileServer.ServeHTTP(rw, req)\n                        })\n                        cst :\u003d httptest.NewUnstartedServer(timeoutHandler)\n                        cst.Config.WriteTimeout \u003d 100 * time.Millisecond\n                        cst.Start()\n                        defer cst.Close()\n\n                        wg.Add(1)\n                        go func() {\n                                \u003c-time.After(cst.Config.WriteTimeout * 2)\n                                wg.Done()\n                        }()\n\n                        res, err :\u003d cst.Client().Get(cst.URL + filename)\n                        if !errors.Is(err, io.EOF) {\n                                t.Fatalf(\"got %v, want io.EOF\", err)\n                        }\n                        if res !\u003d nil \u0026\u0026 res.Body !\u003d nil {\n                                res.Body.Close()\n                        }\n                })\n        }\n}",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "858dd293_eba6f7c4",
        "filename": "src/net/http/fs_test.go",
        "patchSetId": 3
      },
      "lineNbr": 1422,
      "author": {
        "id": 27462
      },
      "writtenOn": "2021-02-02T02:47:19Z",
      "side": 1,
      "message": "Thanks for review!\n\nI updated the filename from response.example to file-bigger-than-512 and used `Subtests` to run cases.\n\nBut I doesn\u0027t use sync.WaitGroup to sync because `time.Sleep` is clear :P.\n\n```go\n// sync goroutine\ngo func() {\n   \u003c-time.After(cst.Config.WriteTimeout * 2)\n   wg.Done()\n}()\n```\n\nEven if the go schedule can make sure that `cst.Client().Get()` and `sync goroutine` can run at the same time, it maybe introduce unpredictable behaviour when `sync goroutine` finish before `cst.Client().Get()`. Therefore, `time.Sleep` in handler is more clear and reliable to me. WDYT?",
      "parentUuid": "ddda5c9c_565ad901",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2c5549c1_b842753c",
        "filename": "src/net/http/fs_test.go",
        "patchSetId": 3
      },
      "lineNbr": 1422,
      "author": {
        "id": 5137
      },
      "writtenOn": "2021-02-02T03:01:16Z",
      "side": 1,
      "message": "The point of that explicit synchronization was to ensure that we have predictable behavior, because in the past I found that sleeps introduce flakes which is why I suggested avoiding them outside of the handler. Please see prior flakes with: #35051 and CL 200518 which was fixed with CL 208477. Thank you.",
      "parentUuid": "858dd293_eba6f7c4",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0560540d_ad7033d1",
        "filename": "src/net/http/fs_test.go",
        "patchSetId": 3
      },
      "lineNbr": 1422,
      "author": {
        "id": 27462
      },
      "writtenOn": "2021-02-02T04:06:55Z",
      "side": 1,
      "message": "The link is helpful! It is good pattern for testing ServerReply when Timeout. It uses block channel to let `ctx.Done()` return error. But in this case, it needs server to flush the response to client ðŸ˜­.\n\nI was thinking that is like\n\n```go\n// the part of the case\n\nstartCh :\u003d make(chan struct{}, 0)\nwaitCh :\u003d make(chan struct{}, 0)\n\ntimeoutHandler :\u003d HandlerFunc(func(rw ResponseWriter, req *Request) {\n    close(startCh)\n    \u003c-waitCh\n    fileServer.ServeHTTP(rw, req)\n})\n\ngo func() {\n   \u003c-startCh\n   time.Sleep(2 * cst.Config.WriteTimeout)\n   close(waitCh)\n}()\n\n...\n```\n\nBut it seems that it is still flaky when builder is busy...",
      "parentUuid": "2c5549c1_b842753c",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "629e3679_2669d776",
        "filename": "src/net/http/fs_test.go",
        "patchSetId": 3
      },
      "lineNbr": 1422,
      "author": {
        "id": 5137
      },
      "writtenOn": "2021-02-02T09:05:34Z",
      "side": 1,
      "message": "I think this will work, but please remove the 0 in the channel creation code. Thanks!",
      "parentUuid": "0560540d_ad7033d1",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "166535d1_67498da8",
        "filename": "src/net/http/fs_test.go",
        "patchSetId": 3
      },
      "lineNbr": 1437,
      "author": {
        "id": 5137
      },
      "writtenOn": "2021-02-01T19:29:20Z",
      "side": 1,
      "message": "This code won\u0027t run the next test if it fails on the first, we perhaps need a sub test.",
      "revId": "8ccdd228b5fd20d2100d8676632e8b7f0b64766a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    }
  ]
}