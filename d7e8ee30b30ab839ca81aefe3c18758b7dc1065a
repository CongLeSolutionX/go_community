{
  "comments": [
    {
      "key": {
        "uuid": "2ec48060_fb508753",
        "filename": "src/runtime/mgcmark.go",
        "patchSetId": 3
      },
      "lineNbr": 848,
      "author": {
        "id": 5400
      },
      "writtenOn": "2016-04-05T18:40:20Z",
      "side": 1,
      "message": "Global mutexes in common operations worry me. There are chances we will need to rework this later (think of 64 core machine with tens of gigs heap).\n\nMore elaborate solutions are possible (for example, building per-P lists, or grow-only lists, or per-P lists with local freelists of remotely freed slots). But I would try a simpler solution. I don\u0027t see any fast path exits in markroot for clean stacks, we seem to execute systemstack+traceback+some minor stuff for clean stacks. So I would try to add just gcscanvalid per-G flag and short circuit markroot on that flag. Additionally we can add a very conservative batching of stack scanning, if we are talking about 300K goroutines, batch of 10 or so goroutines looks like a reasonable thing. Both these optimizations should reduce per-G overhead to few nanoseconds (while being reasonably simple).\n\nIf that does not help, I would try per-P grow-only lists. All 300K goroutines are unlikely to run during concurrent phase. And if there is high goroutine creation/exit rate, then these goroutines will reuse the same G\u0027s so they won\u0027t grow the lists.",
      "revId": "d7e8ee30b30ab839ca81aefe3c18758b7dc1065a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "2ec48060_5b197bc0",
        "filename": "src/runtime/mgcmark.go",
        "patchSetId": 3
      },
      "lineNbr": 848,
      "author": {
        "id": 5400
      },
      "writtenOn": "2016-04-05T18:42:24Z",
      "side": 1,
      "message": "On second thought, can\u0027t we limit a per-P list? If a P dirtied, say, 1000 stacks, it could scan one of these stacks and replace the slot with a new dirty stack. Looks better then leaving massive amounts of dirty stacks for mark termination.",
      "parentUuid": "2ec48060_fb508753",
      "revId": "d7e8ee30b30ab839ca81aefe3c18758b7dc1065a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "084ed4ab_3ce2d1ed",
        "filename": "src/runtime/mgcmark.go",
        "patchSetId": 3
      },
      "lineNbr": 848,
      "author": {
        "id": 5167
      },
      "writtenOn": "2016-04-18T22:20:57Z",
      "side": 1,
      "message": "I\u0027m no fan of global locks myself, but this one is acquired at most once per non-idle goroutine per GC cycle, so I\u0027d be surprised if it\u0027s an issue. If there\u0027s evidence that it is an issue, I\u0027m happy to rework it into something more complex but more scalable. Another way to do this is simply to shard the list by a hash of gp (then gp doesn\u0027t have to keep track of which per-P list it\u0027s on).\n\nI\u0027m not sure I understand your per-G flag suggestion. If I\u0027m reading it right, that\u0027s *exactly* what we do now, which costs us 34ns, which is already too expensive, and is what this CL is moving away from. The point of the rescan list is to attack this at an asymptotic level and bring the STW cost of an idle G to 0. My first version of this CL tried to improve this by simply pulling the gcscanvalid out into a contiguous array, but while that helped, it didn\u0027t help enough. That\u0027s what led me to conclude that improving the asymptotics of this was really the only way to go.\n\nI had a grow-only list (though not per-P) in an earlier version, too, but ran into races involving dead goroutine reuse that I concluded were unresolvable without adding far more synchronization overhead that I was comfortable with.\n\n\u003e On second thought, can\u0027t we limit a per-P list? If a P dirtied, say, 1000 stacks, it could scan one of these stacks and replace the slot with a new dirty stack. Looks better then leaving massive amounts of dirty stacks for mark termination.\n\nThis is solving a different problem, though one we\u0027re definitely interested in solving. Your suggestion is actually one of the solutions we\u0027ve kicked around. Beyond that, we were thinking of bounding the stack rescanning work, which is quite easy to estimate pretty well, rather than the number of stacks; and borrowing some distributed GC tricks from Sapphire to further cut down the set of stacks you have to rescan. But that\u0027s clearly not going to happen for Go 1.7.",
      "parentUuid": "2ec48060_fb508753",
      "revId": "d7e8ee30b30ab839ca81aefe3c18758b7dc1065a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0815f483_c4aade94",
        "filename": "src/runtime/mgcmark.go",
        "patchSetId": 3
      },
      "lineNbr": 848,
      "author": {
        "id": 5400
      },
      "writtenOn": "2016-04-19T06:17:17Z",
      "side": 1,
      "message": "\u003e but this one is acquired at most once per non-idle goroutine per GC cycle, so I\u0027d be surprised if it\u0027s an issue.\n\nYou call dequeueRescan in goexit. It means that the lock can be acquired every 100ns per P, regardless of number of goorutines. That\u0027s going to kill the system.\n\n\u003e If there\u0027s evidence that it is an issue\n\nIs there evidence otherwise? :)\n\n\u003e I\u0027m not sure I understand your per-G flag suggestion. If I\u0027m reading it right, that\u0027s *exactly* what we do now\n\nWhere do we check the flag now? I\u0027ve searched for it, but did not find. 34ns sounds like we are checking it in the wrong place. Should be easily fixable.\nAlong with batching we should be able to get the overhead down to few ns.\n\n\u003e This is solving a different problem\n\nWhy? As far as I see it solves both problems. We will not have more than 1000 goroutines for re-checking.\n\n\u003e and borrowing some distributed GC tricks from Sapphire to further cut down the set of stacks you have to rescan. But that\u0027s clearly not going to happen for Go 1.7.\n\nOK, what about just bounding number of dirty stacks per P?",
      "parentUuid": "084ed4ab_3ce2d1ed",
      "revId": "d7e8ee30b30ab839ca81aefe3c18758b7dc1065a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "28db983a_ddfd8b15",
        "filename": "src/runtime/mgcmark.go",
        "patchSetId": 3
      },
      "lineNbr": 848,
      "author": {
        "id": 5167
      },
      "writtenOn": "2016-04-19T14:48:36Z",
      "side": 1,
      "message": "\u003e \u003e but this one is acquired at most once per non-idle goroutine per GC cycle, so I\u0027d be surprised if it\u0027s an issue.\n \u003e \n \u003e You call dequeueRescan in goexit. It means that the lock can be acquired every 100ns per P, regardless of number of goorutines. That\u0027s going to kill the system.\n\nWhere does the 100ns come from? That sounds like a microbenchmark that does nothing but start and exit goroutines.\n\n \u003e \u003e If there\u0027s evidence that it is an issue\n \u003e \n \u003e Is there evidence otherwise? :)\n\nThat sounds like an argument from my dissertation. :)\n\n \u003e \u003e I\u0027m not sure I understand your per-G flag suggestion. If I\u0027m reading it right, that\u0027s *exactly* what we do now\n \u003e \n \u003e Where do we check the flag now? I\u0027ve searched for it, but did not find. 34ns sounds like we are checking it in the wrong place. Should be easily fixable.\n \u003e Along with batching we should be able to get the overhead down to few ns.\n\nIt\u0027s in scanstack. We could certainly lift that check higher, which would shave off time. But a non-trivial amount of that cost is taking the cache miss just to get the flag field out of the g and that cost will be there with any flag-based approach.\n\n \u003e \u003e This is solving a different problem\n \u003e \n \u003e Why? As far as I see it solves both problems. We will not have more than 1000 goroutines for re-checking.\n \u003e \n \u003e \u003e and borrowing some distributed GC tricks from Sapphire to further cut down the set of stacks you have to rescan. But that\u0027s clearly not going to happen for Go 1.7.\n \u003e \n \u003e OK, what about just bounding number of dirty stacks per P?\n\nI\u0027m not saying we shouldn\u0027t do something about bounding dirty stacks. We definitely should. I\u0027m just saying that there\u0027s less than 2 weeks until the freeze, this CL is already reducing pause times by nearly an order of magnitude for real workloads, and there\u0027s plenty of other stuff to do.",
      "parentUuid": "0815f483_c4aade94",
      "revId": "d7e8ee30b30ab839ca81aefe3c18758b7dc1065a",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705",
      "unresolved": false
    }
  ]
}