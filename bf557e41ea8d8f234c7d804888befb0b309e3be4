{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "2f778b7b_5f22c6d6",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 34725
      },
      "writtenOn": "2020-11-19T11:54:43Z",
      "side": 1,
      "message": "PTAL",
      "revId": "bf557e41ea8d8f234c7d804888befb0b309e3be4",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "30e2f340_be24ea84",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5206
      },
      "writtenOn": "2020-11-19T16:04:41Z",
      "side": 1,
      "message": "It doesn\u0027t seem like a good idea to have a pool of pipes that never goes away.  That would mean that if the program has some sort of phase change it would be left with a bunch of descriptors that are never closed.  Compare, for example, to sync.Pool.",
      "revId": "bf557e41ea8d8f234c7d804888befb0b309e3be4",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "6b8bc8ca_0627ab80",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 34725
      },
      "writtenOn": "2020-11-19T16:08:07Z",
      "side": 1,
      "message": "But if we store pipes in sync.Pool, those pipes will still not be closed after the GC to clean up all objects in sync.Pool.",
      "parentUuid": "30e2f340_be24ea84",
      "revId": "bf557e41ea8d8f234c7d804888befb0b309e3be4",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "83cce521_293f19b1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 34725
      },
      "writtenOn": "2020-11-19T16:13:32Z",
      "side": 1,
      "message": "Maybe set up an individual goroutine to scan the pipe pool and close all pipes periodically?",
      "revId": "bf557e41ea8d8f234c7d804888befb0b309e3be4",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "02abc139_f23d80d9",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5206
      },
      "writtenOn": "2020-11-19T16:45:05Z",
      "side": 1,
      "message": "Sorry, I didn\u0027t mean to literally use a sync.Pool (though that could perhaps work in conjunction with a finalizer).  I meant to look at what sync.Pool does, which is to discard pool contents over time.",
      "parentUuid": "6b8bc8ca_0627ab80",
      "revId": "bf557e41ea8d8f234c7d804888befb0b309e3be4",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a655d7ec_dde91873",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 34725
      },
      "writtenOn": "2020-11-19T17:02:38Z",
      "side": 1,
      "message": "OK, so which do you think is the better idea, sync.Pool + Finalizer or pipe list with goroutine to clean up pipes like I said before.",
      "parentUuid": "02abc139_f23d80d9",
      "revId": "bf557e41ea8d8f234c7d804888befb0b309e3be4",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "dcd700a3_3772fa00",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 27279
      },
      "writtenOn": "2020-11-19T20:03:20Z",
      "side": 1,
      "message": "I agree that when splice is called, it is usually called many times. This is certainly true for the systems I am currently working on for my client.\n\nI think using sync.Pool would be great, because sync.Pool has many desirable properties, such as per-P locality, discarding elements over time, and smoothing out discard behavior using a multi layered victim cache. For a bespoke solution, these either cannot be implemented easily at all (the per-P element), or require substantial additional work (discarding over time, smoothing out discards).\n\nCeating a pipe can fail, and the New function used in the pool needs to be able to deal with this somehow. The New function cannot signal an error, so we need to make sure that we can deal with this case cleanly. In particular, we are interested in how to deal with EMFILE and ENFILE. From my reading of pipe2(2), these are the only errors we should be concerned with. Even if creating the pipe fails, we must be able to try the conventional read + write path as a fallback, because perhaps creating the pipe failed because we ran out of available file descriptors, but we can still work with the ones we currently have open. Maybe the New function can return nil to signal this special case. We swallow the error when we do that, but we currently swallow it in the net package anyway, so I think it\u0027s OK.\n\nAdditionally, special attention is needed in order to ensure that after a call to Splice, when a pipe is returned to the pool, it has no outstanding data that might corrupt future uses.",
      "parentUuid": "a655d7ec_dde91873",
      "revId": "bf557e41ea8d8f234c7d804888befb0b309e3be4",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "803d925a_1a1663ef",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 34725
      },
      "writtenOn": "2020-11-20T07:16:30Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "dcd700a3_3772fa00",
      "revId": "bf557e41ea8d8f234c7d804888befb0b309e3be4",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    }
  ]
}